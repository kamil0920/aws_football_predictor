{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import json\n",
    "import logging\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import boto3\n",
    "import os\n",
    "import ipytest\n",
    "\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "CODE_FOLDER = Path(\"code\")\n",
    "CODE_FOLDER.mkdir(parents=True, exist_ok=True)\n",
    "INFERENCE_CODE_FOLDER = CODE_FOLDER / \"inference\"\n",
    "INFERENCE_CODE_FOLDER.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "sys.path.extend([f\"./{CODE_FOLDER}\", f\"./{INFERENCE_CODE_FOLDER}\"])\n",
    "\n",
    "ipytest.autoconfig(raise_on_error=True)\n",
    "\n",
    "logging.getLogger('sagemaker').setLevel(logging.ERROR)\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T19:39:10.898838Z",
     "start_time": "2024-05-13T19:39:10.838287Z"
    }
   },
   "id": "6beb300bf7e34dc7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "source": [
    "BUCKET = os.environ[\"BUCKET\"]\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "# !aws s3api create-bucket --bucket BUCKET --create-bucket-configuration LocationConstraint=region"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T19:39:10.917409Z",
     "start_time": "2024-05-13T19:39:10.899777Z"
    }
   },
   "id": "bd1ac55d994fc2d1",
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "sagemaker_client = boto3.client(\"sagemaker\")\n",
    "iam_client = boto3.client(\"iam\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T19:39:10.970131Z",
     "start_time": "2024-05-13T19:39:10.918846Z"
    }
   },
   "id": "9ecad0246ed456da",
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "source": [
    "from sagemaker.workflow.pipeline_context import PipelineSession, LocalPipelineSession\n",
    "\n",
    "DUMMY_ROLE = \"arn:aws:iam::111111111111:role/service-role/AmazonSageMaker-ExecutionRole-11111111111111\"\n",
    "S3_LOCATION = f\"s3://{BUCKET}/football\"\n",
    "role = os.environ[\"ROLE\"]\n",
    "LOCAL_MODE = False\n",
    "\n",
    "architecture = !(uname -m)\n",
    "IS_ARM64_ARCHITECTURE = architecture[0] == \"arm64\"\n",
    "\n",
    "if LOCAL_MODE:\n",
    "    config = {\n",
    "        \"session\": LocalPipelineSession(default_bucket=BUCKET),\n",
    "        \"instance_type\": \"local\",\n",
    "        \"image\": \"sagemaker-xgboost-training-toolkit-local\" if IS_ARM64_ARCHITECTURE else None\n",
    "    }\n",
    "else:\n",
    "    config = {\n",
    "        \"session\": PipelineSession(default_bucket=BUCKET) if not LOCAL_MODE else None,\n",
    "        \"instance_type\": \"ml.c5.4xlarge\",\n",
    "        \"image\": None,\n",
    "    }\n",
    "\n",
    "config[\"framework_version\"] = \"1.7-1\"\n",
    "config[\"py_version\"] = \"py310\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T19:39:11.037105Z",
     "start_time": "2024-05-13T19:39:10.971605Z"
    }
   },
   "id": "ee6bc054dfdcbab",
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "source": [
    "df_local_path = str(os.environ['DATA_FILEPATH_X'])\n",
    "y_local_path = str(os.environ['DATA_FILEPATH_Y'])\n",
    "\n",
    "# S3Uploader.upload(local_path=df_local_path, desired_s3_uri=f\"{S3_LOCATION}/data\", sagemaker_session=config['session'])\n",
    "# S3Uploader.upload(local_path=y_local_path, desired_s3_uri=f\"{S3_LOCATION}/data\", sagemaker_session=config['session'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T19:39:11.055149Z",
     "start_time": "2024-05-13T19:39:11.038181Z"
    }
   },
   "id": "54a0a7017c5afb2f",
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "source": [
    "from sagemaker.workflow.steps import CacheConfig\n",
    "\n",
    "cache_config = CacheConfig(enable_caching=True, expire_after=\"15d\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T19:39:11.069078Z",
     "start_time": "2024-05-13T19:39:11.056316Z"
    }
   },
   "id": "36f2b2ff5af7f7bf",
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "source": [
    "from sagemaker.workflow.pipeline_definition_config import PipelineDefinitionConfig\n",
    "from sagemaker.sklearn import SKLearnProcessor\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.parameters import ParameterString\n",
    "\n",
    "pipeline_definition_config = PipelineDefinitionConfig(use_custom_job_prefix=True)\n",
    "\n",
    "dataset_location = ParameterString(\n",
    "    name=\"dataset_location\",\n",
    "    default_value=f\"{S3_LOCATION}/data\",\n",
    ")\n",
    "\n",
    "processor = SKLearnProcessor(\n",
    "    base_job_name=\"split-and-transform-data\",\n",
    "    framework_version=\"1.2-1\",\n",
    "    instance_type=config[\"instance_type\"],\n",
    "    instance_count=1,\n",
    "    role=role,\n",
    "    sagemaker_session=config['session'],\n",
    ")\n",
    "\n",
    "split_and_transform_data_step = ProcessingStep(\n",
    "    name=\"split-and-transform-data\",\n",
    "    step_args=processor.run(\n",
    "        code=f\"{CODE_FOLDER}/preprocessor.py\",\n",
    "        inputs=[\n",
    "            ProcessingInput(source=dataset_location, destination=\"/opt/ml/processing/input\"),\n",
    "        ],\n",
    "        outputs=[\n",
    "            ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\"),\n",
    "            ProcessingOutput(output_name=\"validation\", source=\"/opt/ml/processing/validation\"),\n",
    "            ProcessingOutput(output_name=\"test\", source=\"/opt/ml/processing/test\"),\n",
    "            ProcessingOutput(output_name=\"model\", source=\"/opt/ml/processing/model\"),\n",
    "            ProcessingOutput(output_name=\"train-baseline\", source=\"/opt/ml/processing/train-baseline\"),\n",
    "            ProcessingOutput(output_name=\"test-baseline\", source=\"/opt/ml/processing/test-baseline\"),\n",
    "        ]\n",
    "    ),\n",
    "    cache_config=cache_config,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T19:39:11.095327Z",
     "start_time": "2024-05-13T19:39:11.070202Z"
    }
   },
   "id": "9c975fc0201b8f4d",
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "source": [
    "from sagemaker.workflow.steps import TrainingStep\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "\n",
    "def create_training_step(estimator):\n",
    "    \"\"\"Create a SageMaker TrainingStep using the provided estimator.\"\"\"\n",
    "    return TrainingStep(\n",
    "        name=\"train-model\",\n",
    "        step_args=estimator.fit(\n",
    "            inputs={\n",
    "                \"train\": TrainingInput(\n",
    "                    s3_data=split_and_transform_data_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                        \"train\"\n",
    "                    ].S3Output.S3Uri,\n",
    "                    content_type=\"text/csv\",\n",
    "                ),\n",
    "                \"validation\": TrainingInput(\n",
    "                    s3_data=split_and_transform_data_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                        \"validation\"\n",
    "                    ].S3Output.S3Uri,\n",
    "                    content_type=\"text/csv\",\n",
    "                ),\n",
    "            },\n",
    "        ),\n",
    "        cache_config=cache_config,\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T19:39:11.109416Z",
     "start_time": "2024-05-13T19:39:11.096343Z"
    }
   },
   "id": "5dd9879e78a475aa",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T19:39:11.123118Z",
     "start_time": "2024-05-13T19:39:11.110469Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import shutil\n",
    "# \n",
    "# (CODE_FOLDER / \"containers\" / \"training\").mkdir(parents=True, exist_ok=True)\n",
    "# shutil.copy2(\n",
    "#     CODE_FOLDER / \"train.py\",\n",
    "#     CODE_FOLDER / \"containers\" / \"training\" / \"train.py\",\n",
    "# )"
   ],
   "id": "7a57d03bcffe3eec",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T19:39:11.137781Z",
     "start_time": "2024-05-13T19:39:11.124407Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# %%writefile {CODE_FOLDER}/containers/training/requirements.txt\n",
    "# # | filename: requirements.txt\n",
    "# # | code-line-numbers: true\n",
    "# \n",
    "# sagemaker-training\n",
    "# xgboost\n",
    "# pandas\n",
    "# numpy\n",
    "# scikit-learn"
   ],
   "id": "1ce1f5e526fcb4d0",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T19:39:11.156932Z",
     "start_time": "2024-05-13T19:39:11.138801Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# %%writefile {CODE_FOLDER}/containers/training/Dockerfile\n",
    "# # | filename: Dockerfile\n",
    "# # | code-line-numbers: true\n",
    "# \n",
    "# FROM python:3.10-slim\n",
    "# \n",
    "# RUN apt-get -y update && apt-get install -y --no-install-recommends \\\n",
    "#     python3 \\\n",
    "#     build-essential \\\n",
    "#     libssl-dev\n",
    "# \n",
    "# # Let's install the required Python packages from \n",
    "# # the requirements.txt file.\n",
    "# COPY requirements.txt .\n",
    "# RUN pip install --user --upgrade pip\n",
    "# RUN pip3 install -r requirements.txt\n",
    "# \n",
    "# # We are going to be running the training script\n",
    "# # as the entrypoint of this container.\n",
    "# COPY train.py /opt/ml/code/train.py\n",
    "# ENV SAGEMAKER_PROGRAM train.py"
   ],
   "id": "68864cccad986a05",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T19:39:11.176581Z",
     "start_time": "2024-05-13T19:39:11.158155Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# \n",
    "# if not LOCAL_MODE:\n",
    "#     # If we aren't running the code in Local Mode, we need\n",
    "#     # to specify we want to build the Docker image for the\n",
    "#     # linux/amd64 architecture before uploading it to ECR.\n",
    "#     print(\"Building Docker image for linux/amd64 architecture...\")\n",
    "# \n",
    "#     !docker build --platform=\"linux/amd64\" -t $IMAGE_NAME $CODE_FOLDER/containers/training/\n",
    "# else:\n",
    "#     # If we are running in Local Mode, we can use the\n",
    "#     # default Docker build command.\n",
    "#     print(\"Building Docker image for arm64 architecture...\")\n",
    "# \n",
    "#     !docker build -t $IMAGE_NAME $CODE_FOLDER/containers/training/"
   ],
   "id": "dcb803dd2d6b0c01",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T19:39:11.195791Z",
     "start_time": "2024-05-13T19:39:11.177734Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# %%bash -s \"$LOCAL_MODE\" \"$IMAGE_NAME\"\n",
    "# # | eval: false\n",
    "# \n",
    "# algorithm_name=$2\n",
    "# account=$(aws sts get-caller-identity --query Account --output text)\n",
    "# \n",
    "# # Get the region defined in the current configuration\n",
    "# # (default to us-east-1 if none defined)\n",
    "# region=$(aws configure get region)\n",
    "# region=${region:-us-east-1}\n",
    "# \n",
    "# repository=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "# \n",
    "# # We only want to push the Docker image to ECR if\n",
    "# # we are not running in Local Mode.\n",
    "# if [ $1 = \"False\" ]\n",
    "# then\n",
    "#     # Create the repository if it doesn't exist in ECR\n",
    "#     aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "#     if [ $? -ne 0 ]\n",
    "#     then\n",
    "#         aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "#     fi\n",
    "# \n",
    "#     # Get the login command from ECR to run the\n",
    "#     # Docker push command.\n",
    "#     aws ecr get-login-password --region ${region}|docker login --username AWS --password-stdin ${repository}\n",
    "# \n",
    "#     # Push the Docker image to the ECR repository\n",
    "#     docker tag ${algorithm_name} ${repository}\n",
    "#     docker push ${repository}\n",
    "# fi"
   ],
   "id": "4d2735ea03f27968",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T19:39:11.210406Z",
     "start_time": "2024-05-13T19:39:11.197472Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # sts - security token service\n",
    "# account_id = boto3.client(\"sts\").get_caller_identity().get(\"Account\")\n",
    "# tag = \":latest\"\n",
    "# \n",
    "# uri_suffix = \"amazonaws.com\"\n",
    "# if region in [\"cn-north-1\", \"cn-northwest-1\"]:\n",
    "#     uri_suffix = \"amazonaws.com.cn\"\n",
    "# \n",
    "# training_container_image = (\n",
    "#     IMAGE_NAME\n",
    "#     if LOCAL_MODE\n",
    "#     else f\"{account_id}.dkr.ecr.{region}.amazonaws.com/{IMAGE_NAME}{tag}\"\n",
    "# )\n",
    "# \n",
    "# training_container_image"
   ],
   "id": "f9a1b4e34dc5b4e1",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T19:43:09.752772Z",
     "start_time": "2024-05-13T19:39:11.211315Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from program.code.containers.SageMakerContainerBuilder import SageMakerContainerBuilder\n",
    "\n",
    "IMAGE_NAME = \"xgb-clf-custom-training-container\"\n",
    "\n",
    "builder = SageMakerContainerBuilder(\n",
    "    code_folder=CODE_FOLDER, \n",
    "    image_name=IMAGE_NAME,\n",
    "    local_mode=LOCAL_MODE\n",
    ")\n",
    "\n",
    "training_container_image = builder.build_and_push()\n",
    "print(training_container_image)"
   ],
   "id": "c589837afe0d6d2b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "#0 building with \"default\" instance using docker driver\n",
      "\n",
      "#1 [internal] load build definition from Dockerfile\n",
      "#1 transferring dockerfile: 373B done\n",
      "#1 DONE 0.0s\n",
      "\n",
      "#2 [internal] load metadata for docker.io/library/python:3.10-slim\n",
      "#2 DONE 1.3s\n",
      "\n",
      "#3 [internal] load .dockerignore\n",
      "#3 transferring context: 2B done\n",
      "#3 DONE 0.0s\n",
      "\n",
      "#4 [1/6] FROM docker.io/library/python:3.10-slim@sha256:161d1e3deddba156d7834d15e6fe4d010b3b6f69f18ee1cfba9348e712f4a4ba\n",
      "#4 DONE 0.0s\n",
      "\n",
      "#5 [internal] load build context\n",
      "#5 transferring context: 133B done\n",
      "#5 DONE 0.0s\n",
      "\n",
      "#6 [2/6] RUN apt-get -y update && apt-get install -y --no-install-recommends     python3     build-essential     libssl-dev\n",
      "#6 CACHED\n",
      "\n",
      "#7 [3/6] COPY requirements.txt .\n",
      "#7 DONE 0.0s\n",
      "\n",
      "#8 [4/6] RUN pip install --user --upgrade pip\n",
      "#8 1.115 Requirement already satisfied: pip in /usr/local/lib/python3.10/site-packages (23.0.1)\n",
      "#8 1.368 Collecting pip\n",
      "#8 1.556   Downloading pip-24.0-py3-none-any.whl (2.1 MB)\n",
      "#8 1.789      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.1/2.1 MB 9.3 MB/s eta 0:00:00\n",
      "#8 1.824 Installing collected packages: pip\n",
      "#8 2.585   WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH.\n",
      "#8 2.585   Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "#8 2.592 Successfully installed pip-24.0\n",
      "#8 2.592 WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "#8 2.807 \n",
      "#8 2.807 [notice] A new release of pip is available: 23.0.1 -> 24.0\n",
      "#8 2.807 [notice] To update, run: pip install --upgrade pip\n",
      "#8 DONE 3.0s\n",
      "\n",
      "#9 [5/6] RUN pip3 install -r requirements.txt\n",
      "#9 0.643 Collecting sagemaker-training (from -r requirements.txt (line 2))\n",
      "#9 0.806   Downloading sagemaker_training-4.7.4.tar.gz (59 kB)\n",
      "#9 0.850      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 59.4/59.4 kB 1.2 MB/s eta 0:00:00\n",
      "#9 0.866   Preparing metadata (setup.py): started\n",
      "#9 1.206   Preparing metadata (setup.py): finished with status 'done'\n",
      "#9 1.288 Collecting xgboost (from -r requirements.txt (line 3))\n",
      "#9 1.322   Downloading xgboost-2.0.3-py3-none-manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
      "#9 1.536 Collecting pandas (from -r requirements.txt (line 4))\n",
      "#9 1.571   Downloading pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "#9 1.768 Collecting numpy (from -r requirements.txt (line 5))\n",
      "#9 1.803   Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "#9 1.815      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 61.0/61.0 kB 6.3 MB/s eta 0:00:00\n",
      "#9 1.920 Collecting scikit-learn (from -r requirements.txt (line 6))\n",
      "#9 1.958   Downloading scikit_learn-1.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "#9 2.351 Collecting boto3 (from sagemaker-training->-r requirements.txt (line 2))\n",
      "#9 2.385   Downloading boto3-1.34.104-py3-none-any.whl.metadata (6.6 kB)\n",
      "#9 2.443 Collecting six (from sagemaker-training->-r requirements.txt (line 2))\n",
      "#9 2.478   Downloading six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "#9 2.484 Requirement already satisfied: pip in /root/.local/lib/python3.10/site-packages (from sagemaker-training->-r requirements.txt (line 2)) (24.0)\n",
      "#9 2.539 Collecting retrying>=1.3.3 (from sagemaker-training->-r requirements.txt (line 2))\n",
      "#9 2.612   Downloading retrying-1.3.4-py3-none-any.whl.metadata (6.9 kB)\n",
      "#9 2.754 Collecting gevent (from sagemaker-training->-r requirements.txt (line 2))\n",
      "#9 2.792   Downloading gevent-24.2.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "#9 2.842 Collecting inotify_simple==1.2.1 (from sagemaker-training->-r requirements.txt (line 2))\n",
      "#9 2.878   Downloading inotify_simple-1.2.1.tar.gz (7.9 kB)\n",
      "#9 2.882   Preparing metadata (setup.py): started\n",
      "#9 3.019   Preparing metadata (setup.py): finished with status 'done'\n",
      "#9 3.087 Collecting werkzeug>=0.15.5 (from sagemaker-training->-r requirements.txt (line 2))\n",
      "#9 3.126   Downloading werkzeug-3.0.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "#9 3.189 Collecting paramiko>=2.4.2 (from sagemaker-training->-r requirements.txt (line 2))\n",
      "#9 3.223   Downloading paramiko-3.4.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "#9 3.338 Collecting psutil>=5.6.7 (from sagemaker-training->-r requirements.txt (line 2))\n",
      "#9 3.372   Downloading psutil-5.9.8-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
      "#9 3.577 Collecting protobuf<=3.20.3,>=3.9.2 (from sagemaker-training->-r requirements.txt (line 2))\n",
      "#9 3.610   Downloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (679 bytes)\n",
      "#9 3.734 Collecting scipy>=1.2.2 (from sagemaker-training->-r requirements.txt (line 2))\n",
      "#9 3.770   Downloading scipy-1.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "#9 3.782      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.6/60.6 kB 6.7 MB/s eta 0:00:00\n",
      "#9 4.285 Collecting botocore>=1.31.57 (from sagemaker-training->-r requirements.txt (line 2))\n",
      "#9 4.323   Downloading botocore-1.34.104-py3-none-any.whl.metadata (5.7 kB)\n",
      "#9 4.445 Collecting python-dateutil>=2.8.2 (from pandas->-r requirements.txt (line 4))\n",
      "#9 4.481   Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "#9 4.560 Collecting pytz>=2020.1 (from pandas->-r requirements.txt (line 4))\n",
      "#9 4.595   Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "#9 4.659 Collecting tzdata>=2022.7 (from pandas->-r requirements.txt (line 4))\n",
      "#9 4.694   Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "#9 4.800 Collecting joblib>=1.2.0 (from scikit-learn->-r requirements.txt (line 6))\n",
      "#9 4.834   Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "#9 4.884 Collecting threadpoolctl>=2.0.0 (from scikit-learn->-r requirements.txt (line 6))\n",
      "#9 4.918   Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "#9 5.054 Collecting jmespath<2.0.0,>=0.7.1 (from boto3->sagemaker-training->-r requirements.txt (line 2))\n",
      "#9 5.089   Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "#9 5.144 Collecting s3transfer<0.11.0,>=0.10.0 (from boto3->sagemaker-training->-r requirements.txt (line 2))\n",
      "#9 5.179   Downloading s3transfer-0.10.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "#9 5.278 Collecting urllib3!=2.2.0,<3,>=1.25.4 (from botocore>=1.31.57->sagemaker-training->-r requirements.txt (line 2))\n",
      "#9 5.313   Downloading urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\n",
      "#9 5.398 Collecting bcrypt>=3.2 (from paramiko>=2.4.2->sagemaker-training->-r requirements.txt (line 2))\n",
      "#9 5.431   Downloading bcrypt-4.1.3-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.5 kB)\n",
      "#9 5.637 Collecting cryptography>=3.3 (from paramiko>=2.4.2->sagemaker-training->-r requirements.txt (line 2))\n",
      "#9 5.671   Downloading cryptography-42.0.7-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "#9 5.735 Collecting pynacl>=1.5 (from paramiko>=2.4.2->sagemaker-training->-r requirements.txt (line 2))\n",
      "#9 5.768   Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl.metadata (8.6 kB)\n",
      "#9 6.003 Collecting MarkupSafe>=2.1.1 (from werkzeug>=0.15.5->sagemaker-training->-r requirements.txt (line 2))\n",
      "#9 6.038   Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "#9 6.120 Collecting zope.event (from gevent->sagemaker-training->-r requirements.txt (line 2))\n",
      "#9 6.155   Downloading zope.event-5.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "#9 6.293 Collecting zope.interface (from gevent->sagemaker-training->-r requirements.txt (line 2))\n",
      "#9 6.327   Downloading zope.interface-6.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (42 kB)\n",
      "#9 6.335      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 42.0/42.0 kB 5.9 MB/s eta 0:00:00\n",
      "#9 6.473 Collecting greenlet>=2.0.0 (from gevent->sagemaker-training->-r requirements.txt (line 2))\n",
      "#9 6.507   Downloading greenlet-3.0.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "#9 6.652 Collecting cffi>=1.12 (from cryptography>=3.3->paramiko>=2.4.2->sagemaker-training->-r requirements.txt (line 2))\n",
      "#9 6.688   Downloading cffi-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "#9 6.807 Requirement already satisfied: setuptools in /usr/local/lib/python3.10/site-packages (from zope.event->gevent->sagemaker-training->-r requirements.txt (line 2)) (65.5.1)\n",
      "#9 6.871 Collecting pycparser (from cffi>=1.12->cryptography>=3.3->paramiko>=2.4.2->sagemaker-training->-r requirements.txt (line 2))\n",
      "#9 6.904   Downloading pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "#9 6.977 Downloading xgboost-2.0.3-py3-none-manylinux2014_x86_64.whl (297.1 MB)\n",
      "#9 21.18    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 297.1/297.1 MB 1.9 MB/s eta 0:00:00\n",
      "#9 21.22 Downloading pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "#9 21.66    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.0/13.0 MB 29.0 MB/s eta 0:00:00\n",
      "#9 21.72 Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "#9 22.29    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 18.2/18.2 MB 31.2 MB/s eta 0:00:00\n",
      "#9 22.33 Downloading scikit_learn-1.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
      "#9 22.72    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.1/12.1 MB 30.1 MB/s eta 0:00:00\n",
      "#9 22.76 Downloading boto3-1.34.104-py3-none-any.whl (139 kB)\n",
      "#9 22.77    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 139.3/139.3 kB 19.1 MB/s eta 0:00:00\n",
      "#9 22.81 Downloading botocore-1.34.104-py3-none-any.whl (12.2 MB)\n",
      "#9 23.22    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.2/12.2 MB 29.2 MB/s eta 0:00:00\n",
      "#9 23.26 Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "#9 23.27    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 301.8/301.8 kB 34.7 MB/s eta 0:00:00\n",
      "#9 23.31 Downloading paramiko-3.4.0-py3-none-any.whl (225 kB)\n",
      "#9 23.32    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 225.9/225.9 kB 29.5 MB/s eta 0:00:00\n",
      "#9 23.37 Downloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
      "#9 23.40    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 34.8 MB/s eta 0:00:00\n",
      "#9 23.44 Downloading psutil-5.9.8-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB)\n",
      "#9 23.45    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 288.2/288.2 kB 32.7 MB/s eta 0:00:00\n",
      "#9 23.49 Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "#9 23.50    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 229.9/229.9 kB 32.4 MB/s eta 0:00:00\n",
      "#9 23.54 Downloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "#9 23.56    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 505.5/505.5 kB 29.2 MB/s eta 0:00:00\n",
      "#9 23.60 Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
      "#9 23.64 Downloading scipy-1.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
      "#9 24.86    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 38.6/38.6 MB 28.4 MB/s eta 0:00:00\n",
      "#9 24.90 Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "#9 24.94 Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "#9 24.98 Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "#9 24.99    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 345.4/345.4 kB 36.3 MB/s eta 0:00:00\n",
      "#9 25.03 Downloading werkzeug-3.0.3-py3-none-any.whl (227 kB)\n",
      "#9 25.04    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 227.3/227.3 kB 42.8 MB/s eta 0:00:00\n",
      "#9 25.08 Downloading gevent-24.2.1-cp310-cp310-manylinux_2_28_x86_64.whl (6.5 MB)\n",
      "#9 25.29    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.5/6.5 MB 30.8 MB/s eta 0:00:00\n",
      "#9 25.33 Downloading bcrypt-4.1.3-cp39-abi3-manylinux_2_28_x86_64.whl (283 kB)\n",
      "#9 25.34    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 283.7/283.7 kB 26.9 MB/s eta 0:00:00\n",
      "#9 25.38 Downloading cryptography-42.0.7-cp39-abi3-manylinux_2_28_x86_64.whl (3.8 MB)\n",
      "#9 25.50    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.8/3.8 MB 34.2 MB/s eta 0:00:00\n",
      "#9 25.54 Downloading greenlet-3.0.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (616 kB)\n",
      "#9 25.56    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 616.0/616.0 kB 32.0 MB/s eta 0:00:00\n",
      "#9 25.60 Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "#9 25.64 Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "#9 25.69 Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
      "#9 25.72    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 856.7/856.7 kB 29.7 MB/s eta 0:00:00\n",
      "#9 25.76 Downloading s3transfer-0.10.1-py3-none-any.whl (82 kB)\n",
      "#9 25.77    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 82.2/82.2 kB 13.4 MB/s eta 0:00:00\n",
      "#9 25.81 Downloading urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
      "#9 25.82    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 121.1/121.1 kB 22.0 MB/s eta 0:00:00\n",
      "#9 25.85 Downloading zope.event-5.0-py3-none-any.whl (6.8 kB)\n",
      "#9 25.90 Downloading zope.interface-6.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (247 kB)\n",
      "#9 25.91    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 247.3/247.3 kB 32.7 MB/s eta 0:00:00\n",
      "#9 25.95 Downloading cffi-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (443 kB)\n",
      "#9 25.96    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 443.9/443.9 kB 36.2 MB/s eta 0:00:00\n",
      "#9 26.00 Downloading pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "#9 26.01    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 117.6/117.6 kB 18.0 MB/s eta 0:00:00\n",
      "#9 26.38 Building wheels for collected packages: sagemaker-training, inotify_simple\n",
      "#9 26.38   Building wheel for sagemaker-training (setup.py): started\n",
      "#9 26.84   Building wheel for sagemaker-training (setup.py): finished with status 'done'\n",
      "#9 26.84   Created wheel for sagemaker-training: filename=sagemaker_training-4.7.4-cp310-cp310-linux_x86_64.whl size=87799 sha256=c6476984c03704ea4125987af37b6a8e4249b58193fe8134c4e3ac93fdc0a47a\n",
      "#9 26.84   Stored in directory: /root/.cache/pip/wheels/1e/c7/10/5791e13010ca211ba2dad38cc2a0bd23490beda845077ffe73\n",
      "#9 26.84   Building wheel for inotify_simple (setup.py): started\n",
      "#9 27.06   Building wheel for inotify_simple (setup.py): finished with status 'done'\n",
      "#9 27.06   Created wheel for inotify_simple: filename=inotify_simple-1.2.1-py3-none-any.whl size=8202 sha256=a62f834e533702f02014815d7d765da17a1a53180e63244873a279041b6fa1ee\n",
      "#9 27.06   Stored in directory: /root/.cache/pip/wheels/78/26/da/4cd6944e4fbc1e90b34b3ac9f2c9768c93c11b92f29f2da5bc\n",
      "#9 27.06 Successfully built sagemaker-training inotify_simple\n",
      "#9 27.29 Installing collected packages: pytz, inotify_simple, zope.interface, zope.event, urllib3, tzdata, threadpoolctl, six, pycparser, psutil, protobuf, numpy, MarkupSafe, joblib, jmespath, greenlet, bcrypt, werkzeug, scipy, retrying, python-dateutil, gevent, cffi, xgboost, scikit-learn, pynacl, pandas, cryptography, botocore, s3transfer, paramiko, boto3, sagemaker-training\n",
      "#9 38.36 Successfully installed MarkupSafe-2.1.5 bcrypt-4.1.3 boto3-1.34.104 botocore-1.34.104 cffi-1.16.0 cryptography-42.0.7 gevent-24.2.1 greenlet-3.0.3 inotify_simple-1.2.1 jmespath-1.0.1 joblib-1.4.2 numpy-1.26.4 pandas-2.2.2 paramiko-3.4.0 protobuf-3.20.3 psutil-5.9.8 pycparser-2.22 pynacl-1.5.0 python-dateutil-2.9.0.post0 pytz-2024.1 retrying-1.3.4 s3transfer-0.10.1 sagemaker-training-4.7.4 scikit-learn-1.4.2 scipy-1.13.0 six-1.16.0 threadpoolctl-3.5.0 tzdata-2024.1 urllib3-2.2.1 werkzeug-3.0.3 xgboost-2.0.3 zope.event-5.0 zope.interface-6.3\n",
      "#9 38.36 WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "#9 DONE 39.6s\n",
      "\n",
      "#10 [6/6] COPY train.py /opt/ml/code/train.py\n",
      "#10 DONE 0.0s\n",
      "\n",
      "#11 exporting to image\n",
      "#11 exporting layers\n",
      "#11 exporting layers 2.1s done\n",
      "#11 writing image sha256:6435213bdd22dbf4ebb6a16e1bed431151b0b74f0fcfec1bdd74bfb2f5415a2c done\n",
      "#11 naming to docker.io/library/xgb-clf-custom-training-container done\n",
      "#11 DONE 2.1s\n",
      "WARNING! Your password will be stored unencrypted in /home/kmitura/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "The push refers to repository [284415450706.dkr.ecr.eu-north-1.amazonaws.com/xgb-clf-custom-training-container]\n",
      "ccf77faae2c1: Preparing\n",
      "da6a4938c1b5: Preparing\n",
      "ed31f99a521e: Preparing\n",
      "cfac4762ecef: Preparing\n",
      "36d64bcbd30a: Preparing\n",
      "677e54a298ac: Preparing\n",
      "9c444e8c8a76: Preparing\n",
      "aadf04658fc0: Preparing\n",
      "7a75d57a5024: Preparing\n",
      "52ec5a4316fa: Preparing\n",
      "9c444e8c8a76: Waiting\n",
      "7a75d57a5024: Waiting\n",
      "52ec5a4316fa: Waiting\n",
      "677e54a298ac: Waiting\n",
      "aadf04658fc0: Waiting\n",
      "36d64bcbd30a: Layer already exists\n",
      "677e54a298ac: Layer already exists\n",
      "9c444e8c8a76: Layer already exists\n",
      "aadf04658fc0: Layer already exists\n",
      "7a75d57a5024: Layer already exists\n",
      "ccf77faae2c1: Pushed\n",
      "cfac4762ecef: Pushed\n",
      "52ec5a4316fa: Layer already exists\n",
      "ed31f99a521e: Pushed\n",
      "da6a4938c1b5: Pushed\n",
      "latest: digest: sha256:6a9e0772ca28c03f11d1fcd426ab20f51c945c37433b08c77c6c6268976e1c71 size: 2422\n",
      "284415450706.dkr.ecr.eu-north-1.amazonaws.com/xgb-clf-custom-training-container:latest\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T19:43:09.791510Z",
     "start_time": "2024-05-13T19:43:09.774431Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "use_spot_instances = True and not LOCAL_MODE\n",
    "max_run = 500\n",
    "max_wait = 800 if use_spot_instances else None\n",
    "instance_type = config['instance_type']\n",
    "\n",
    "xgb_estimator = Estimator(\n",
    "    image_uri=training_container_image,\n",
    "    instance_count=1,\n",
    "    instance_type=config[\"instance_type\"],\n",
    "    sagemaker_session=config[\"session\"],\n",
    "    role=role,\n",
    "    use_spot_instances=use_spot_instances,\n",
    "    max_run=max_run,\n",
    "    max_wait=max_wait,\n",
    "    disable_profiler=True\n",
    ")\n",
    "\n",
    "xgb_train_model_step = create_training_step(xgb_estimator)"
   ],
   "id": "542afa6921b58b27",
   "outputs": [],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "source": [
    "USE_TUNING_STEP = False and not LOCAL_MODE"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T19:43:09.806490Z",
     "start_time": "2024-05-13T19:43:09.792325Z"
    }
   },
   "id": "51bc8ae0e97f4cfd",
   "outputs": [],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "source": [
    "from sagemaker.tuner import HyperparameterTuner\n",
    "from sagemaker.parameter import IntegerParameter, ContinuousParameter\n",
    "\n",
    "hyperparameter_ranges = {\n",
    "    'eta': ContinuousParameter(min_value=0.05, max_value=0.3, scaling_type=\"Logarithmic\"),\n",
    "    'max_depth': IntegerParameter(min_value=5, max_value=15, scaling_type=\"Auto\"),\n",
    "    'subsample': ContinuousParameter(min_value=0.7, max_value=1.0, scaling_type=\"Auto\"),\n",
    "    'colsample_bytree': ContinuousParameter(min_value=0.7, max_value=1.0, scaling_type=\"Logarithmic\"),\n",
    "    'lambda': ContinuousParameter(min_value=5, max_value=12, scaling_type=\"Logarithmic\"),\n",
    "    'alpha': ContinuousParameter(min_value=1, max_value=10, scaling_type=\"Logarithmic\"),\n",
    "    'min_child_weight': ContinuousParameter(min_value=0.4, max_value=1.0, scaling_type=\"Auto\"),\n",
    "}\n",
    "\n",
    "objective_type = \"Maximize\"\n",
    "metric_definitions = [\n",
    "    {'Name': 'validation:logloss',\n",
    "     'Regex': r\".*\\[[0-9]+\\].*#011validation_0-logloss:([-+]?[0-9]*\\.?[0-9]+(?:[eE][-+]?[0-9]+)?).*\"\n",
    "     },\n",
    "    {'Name': 'validation:f1',\n",
    "     'Regex': 'F1 score: ([0-9\\\\.]+)'\n",
    "     },\n",
    "]\n",
    "metric_name = \"validation:f1\"\n",
    "strategy = \"Bayesian\"\n",
    "\n",
    "tuner = HyperparameterTuner(\n",
    "    estimator=xgb_estimator,\n",
    "    objective_metric_name=metric_name,\n",
    "    objective_type=objective_type,\n",
    "    hyperparameter_ranges=hyperparameter_ranges,\n",
    "    metric_definitions=metric_definitions,\n",
    "    max_jobs=8,\n",
    "    max_parallel_jobs=2,\n",
    "    early_stopping_type='Auto',\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T19:43:09.834908Z",
     "start_time": "2024-05-13T19:43:09.807342Z"
    }
   },
   "id": "a31e770437cfcbb6",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xgboost' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[35], line 27\u001B[0m\n\u001B[1;32m     23\u001B[0m metric_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvalidation:f1\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     24\u001B[0m strategy \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBayesian\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     26\u001B[0m tuner \u001B[38;5;241m=\u001B[39m HyperparameterTuner(\n\u001B[0;32m---> 27\u001B[0m     estimator\u001B[38;5;241m=\u001B[39m\u001B[43mxgboost\u001B[49m,\n\u001B[1;32m     28\u001B[0m     objective_metric_name\u001B[38;5;241m=\u001B[39mmetric_name,\n\u001B[1;32m     29\u001B[0m     objective_type\u001B[38;5;241m=\u001B[39mobjective_type,\n\u001B[1;32m     30\u001B[0m     hyperparameter_ranges\u001B[38;5;241m=\u001B[39mhyperparameter_ranges,\n\u001B[1;32m     31\u001B[0m     metric_definitions\u001B[38;5;241m=\u001B[39mmetric_definitions,\n\u001B[1;32m     32\u001B[0m     max_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m8\u001B[39m,\n\u001B[1;32m     33\u001B[0m     max_parallel_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m,\n\u001B[1;32m     34\u001B[0m     early_stopping_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAuto\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m     35\u001B[0m )\n",
      "\u001B[0;31mNameError\u001B[0m: name 'xgboost' is not defined"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "source": [
    "from sagemaker.workflow.steps import TuningStep\n",
    "\n",
    "tune_model_step = TuningStep(\n",
    "    name=\"tune-model\",\n",
    "    step_args=tuner.fit(\n",
    "        inputs={\n",
    "            \"train\": TrainingInput(\n",
    "                s3_data=split_and_transform_data_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                    \"train\"\n",
    "                ].S3Output.S3Uri,\n",
    "                content_type=\"text/csv\"\n",
    "            ),\n",
    "            \"validation\": TrainingInput(\n",
    "                s3_data=split_and_transform_data_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                    \"validation\"\n",
    "                ].S3Output.S3Uri,\n",
    "                content_type=\"text/csv\"\n",
    "            )\n",
    "        },\n",
    "    ),\n",
    "    cache_config=cache_config\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "473cacc2979587a9",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from sagemaker.xgboost import XGBoostProcessor\n",
    "\n",
    "evaluation_processor = XGBoostProcessor(\n",
    "    base_job_name=\"evaluation-processor\",\n",
    "    image_uri=config[\"image\"],\n",
    "    framework_version=config[\"framework_version\"],\n",
    "    instance_type=config[\"instance_type\"],\n",
    "    instance_count=1,\n",
    "    role=role,\n",
    "    sagemaker_session=config[\"session\"],\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d73cf8acd2617076",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from sagemaker.workflow.properties import PropertyFile\n",
    "\n",
    "evaluation_report = PropertyFile(\n",
    "    name=\"evaluation-report\", output_name=\"evaluation\", path=\"evaluation.json\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f41bc50b964b336a",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model_assets = xgb_train_model_step.properties.ModelArtifacts.S3ModelArtifacts\n",
    "\n",
    "if USE_TUNING_STEP:\n",
    "    model_assets = tune_model_step.get_top_model_s3_uri(\n",
    "        top_k=0,\n",
    "        s3_bucket=config[\"session\"].default_bucket(),\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d55dcab3ed97a887",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "evaluate_model_step = ProcessingStep(\n",
    "    name=\"evaluate-model\",\n",
    "    step_args=evaluation_processor.run(\n",
    "        inputs=[\n",
    "            ProcessingInput(\n",
    "                source=split_and_transform_data_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                    \"test\"\n",
    "                ].S3Output.S3Uri,\n",
    "                destination=\"/opt/ml/processing/test\",\n",
    "            ),\n",
    "            ProcessingInput(\n",
    "                source=model_assets,\n",
    "                destination=\"/opt/ml/processing/model\",\n",
    "            ),\n",
    "        ],\n",
    "        outputs=[\n",
    "            ProcessingOutput(\n",
    "                output_name=\"evaluation\", source=\"/opt/ml/processing/evaluation\"\n",
    "            ),\n",
    "        ],\n",
    "        code=f\"{CODE_FOLDER}/evaluation.py\",\n",
    "    ),\n",
    "    property_files=[evaluation_report],\n",
    "    cache_config=cache_config,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2147eaf6e5f6b450",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# from sagemaker.workflow.pipeline import Pipeline\n",
    "# \n",
    "# session3_pipeline = Pipeline(\n",
    "#     name=\"session3-pipeline\",\n",
    "#     parameters=[dataset_location],\n",
    "#     steps=[\n",
    "#         split_and_transform_data_step,\n",
    "#         tune_model_step if USE_TUNING_STEP else train_model_step,\n",
    "#         evaluate_model_step,\n",
    "#     ],\n",
    "#     pipeline_definition_config=pipeline_definition_config,\n",
    "#     sagemaker_session=config[\"session\"],\n",
    "# )\n",
    "# \n",
    "# session3_pipeline.upsert(role_arn=role)\n",
    "# session3_pipeline.start()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6a397939003d913d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "MODEL_PACKAGE_GROUP = \"football-group\"",
   "metadata": {
    "collapsed": false
   },
   "id": "4a2fd3f026fefc58",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from sagemaker.xgboost.model import XGBoostModel\n",
    "\n",
    "xgb_model = XGBoostModel(\n",
    "    model_data=model_assets,\n",
    "    framework_version=config[\"framework_version\"],\n",
    "    sagemaker_session=config[\"session\"],\n",
    "    role=role,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5cd6b925adb4a12e",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics\n",
    "from sagemaker.workflow.functions import Join\n",
    "\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=Join(\n",
    "            on=\"/\",\n",
    "            values=[\n",
    "                evaluate_model_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                    \"evaluation\"\n",
    "                ].S3Output.S3Uri,\n",
    "                \"evaluation.json\",\n",
    "            ],\n",
    "        ),\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f1255fb2188d37d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from sagemaker.workflow.model_step import ModelStep\n",
    "\n",
    "\n",
    "def create_registration_step(\n",
    "        model,\n",
    "        model_package_group_name,\n",
    "        approval_status=\"Approved\",\n",
    "        content_types=[\"text/csv\"],\n",
    "        response_types=[\"text/csv\"],\n",
    "        model_metrics=None,\n",
    "        drift_check_baselines=None,\n",
    "):\n",
    "    \"\"\"Create a Registration Step using the supplied parameters.\"\"\"\n",
    "    return ModelStep(\n",
    "        name=\"register\",\n",
    "        step_args=model.register(\n",
    "            model_package_group_name=model_package_group_name,\n",
    "            approval_status=approval_status,\n",
    "            model_metrics=model_metrics,\n",
    "            drift_check_baselines=drift_check_baselines,\n",
    "            content_types=content_types,\n",
    "            response_types=response_types,\n",
    "            inference_instances=[config[\"instance_type\"]],\n",
    "            transform_instances=[config[\"instance_type\"]],\n",
    "            framework_version=config[\"framework_version\"],\n",
    "            domain=\"MACHINE_LEARNING\",\n",
    "            task=\"CLASSIFICATION\",\n",
    "            framework=\"XGBOOST\",\n",
    "        ),\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7f97e2d4f10652ce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "transformation_pipeline_model = Join(\n",
    "    on=\"/\",\n",
    "    values=[\n",
    "        split_and_transform_data_step.properties.ProcessingOutputConfig.Outputs[\n",
    "            \"model\"\n",
    "        ].S3Output.S3Uri,\n",
    "        \"model.tar.gz\",\n",
    "    ],\n",
    ")"
   ],
   "id": "c073092448d1ce3f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sagemaker.xgboost import XGBoostModel\n",
    "from sagemaker.sklearn.model import SKLearnModel\n",
    "\n",
    "preprocessing_model = SKLearnModel(\n",
    "    model_data=transformation_pipeline_model,\n",
    "    entry_point=\"preprocessing_component.py\",\n",
    "    source_dir=str(INFERENCE_CODE_FOLDER),\n",
    "    framework_version=\"1.2-1\",\n",
    "    sagemaker_session=config[\"session\"],\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "xgb_model = XGBoostModel(\n",
    "    model_data=model_assets,\n",
    "    framework_version=config[\"framework_version\"],\n",
    "    sagemaker_session=config[\"session\"],\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "post_processing_model = SKLearnModel(\n",
    "    model_data=transformation_pipeline_model,\n",
    "    entry_point=\"postprocessing_component.py\",\n",
    "    source_dir=str(INFERENCE_CODE_FOLDER),\n",
    "    framework_version='1.2-1',\n",
    "    sagemaker_session=config[\"session\"],\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "from sagemaker.pipeline import PipelineModel\n",
    "\n",
    "pipeline_model = PipelineModel(\n",
    "    name=\"inference-model\",\n",
    "    models=[preprocessing_model, xgb_model, post_processing_model],\n",
    "    sagemaker_session=config[\"session\"],\n",
    "    role=role,\n",
    ")"
   ],
   "id": "c23bf2083991a0ab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "GROUND_TRUTH_LOCATION = f\"{S3_LOCATION}/monitoring/groundtruth\"\n",
    "DATA_QUALITY_LOCATION = f\"{S3_LOCATION}/monitoring/data-quality\"\n",
    "MODEL_QUALITY_LOCATION = f\"{S3_LOCATION}/monitoring/model-quality\""
   ],
   "id": "2777c034747d921d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sagemaker.model_monitor.dataset_format import DatasetFormat\n",
    "from sagemaker.workflow.check_job_config import CheckJobConfig\n",
    "from sagemaker.workflow.quality_check_step import (\n",
    "    DataQualityCheckConfig,\n",
    "    QualityCheckStep,\n",
    ")\n",
    "\n",
    "data_quality_baseline_step = QualityCheckStep(\n",
    "    name=\"generate-data-quality-baseline\",\n",
    "    check_job_config=CheckJobConfig(\n",
    "        instance_type=\"ml.c5.xlarge\",\n",
    "        instance_count=1,\n",
    "        volume_size_in_gb=20,\n",
    "        sagemaker_session=config[\"session\"],\n",
    "        role=role,\n",
    "    ),\n",
    "    quality_check_config=DataQualityCheckConfig(\n",
    "        baseline_dataset=split_and_transform_data_step.properties.ProcessingOutputConfig.Outputs[\n",
    "            \"train-baseline\"\n",
    "        ].S3Output.S3Uri,\n",
    "        dataset_format=DatasetFormat.csv(header=True),\n",
    "        output_s3_uri=DATA_QUALITY_LOCATION,\n",
    "    ),\n",
    "    model_package_group_name=MODEL_PACKAGE_GROUP,\n",
    "    skip_check=True,\n",
    "    register_new_baseline=True,\n",
    "    cache_config=cache_config,\n",
    ")"
   ],
   "id": "b558799dac61cc3d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "create_model_step = ModelStep(\n",
    "    name=\"create-model\",\n",
    "    step_args=pipeline_model.create(instance_type=config[\"instance_type\"]),\n",
    ")"
   ],
   "id": "f04d18cc8deba11a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sagemaker.transformer import Transformer\n",
    "\n",
    "transformer = Transformer(\n",
    "    model_name=create_model_step.properties.ModelName,\n",
    "    instance_type=config[\"instance_type\"],\n",
    "    instance_count=1,\n",
    "    strategy=\"MultiRecord\",\n",
    "    accept=\"text/csv\",\n",
    "    assemble_with=\"Line\",\n",
    "    output_path=f\"{S3_LOCATION}/transform\",\n",
    "    sagemaker_session=config[\"session\"],\n",
    ")"
   ],
   "id": "ef6d542c90adcd3b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sagemaker.workflow.steps import TransformStep\n",
    "\n",
    "generate_test_predictions_step = TransformStep(\n",
    "    name=\"generate-test-predictions\",\n",
    "    step_args=transformer.transform(\n",
    "        # We will use the baseline set we generated when we split the data.\n",
    "        # This set corresponds to the test split before the transformation step.\n",
    "        data=split_and_transform_data_step.properties.ProcessingOutputConfig.Outputs[\n",
    "            \"test-baseline\"\n",
    "        ].S3Output.S3Uri,\n",
    "        join_source=\"Input\",\n",
    "        split_type=\"Line\",\n",
    "        content_type=\"text/csv\",\n",
    "        # We want to output the first and the second to last field from\n",
    "        # the joint set. The first field corresponds to the groundtruth,\n",
    "        # and the second to last field corresponds to the prediction.\n",
    "        #\n",
    "        # Notice how the first field is the groundtruth coming from the\n",
    "        # test set. The second to last field is the prediction coming the\n",
    "        # model.\n",
    "        output_filter=\"$[-3,-2]\",\n",
    "    ),\n",
    "    cache_config=cache_config,\n",
    ")"
   ],
   "id": "451fb0386710cbb7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sagemaker.workflow.quality_check_step import ModelQualityCheckConfig\n",
    "\n",
    "model_quality_baseline_step = QualityCheckStep(\n",
    "    name=\"generate-model-quality-baseline\",\n",
    "    check_job_config=CheckJobConfig(\n",
    "        instance_type=\"ml.m5.xlarge\",\n",
    "        instance_count=1,\n",
    "        volume_size_in_gb=20,\n",
    "        sagemaker_session=config[\"session\"],\n",
    "        role=role,\n",
    "    ),\n",
    "    quality_check_config=ModelQualityCheckConfig(\n",
    "        # We are going to use the output of the Transform Step to generate\n",
    "        # the model quality baseline.\n",
    "        baseline_dataset=generate_test_predictions_step.properties.TransformOutput.S3OutputPath,\n",
    "        dataset_format=DatasetFormat.csv(header=False),\n",
    "        # We need to specify the problem type and the fields where the prediction\n",
    "        # and groundtruth are so the process knows how to interpret the results.\n",
    "        problem_type=\"MulticlassClassification\",\n",
    "        # Since the data doesn't have headers, SageMaker will autocreate headers for it.\n",
    "        # _c0 corresponds to the first column, and _c1 corresponds to the second column.\n",
    "        ground_truth_attribute=\"_c0\",\n",
    "        inference_attribute=\"_c1\",\n",
    "        output_s3_uri=MODEL_QUALITY_LOCATION,\n",
    "\n",
    "    ),\n",
    "    model_package_group_name=MODEL_PACKAGE_GROUP,\n",
    "    skip_check=True,\n",
    "    register_new_baseline=True,\n",
    "    cache_config=cache_config,\n",
    ")"
   ],
   "id": "f113a0f94469d137",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sagemaker.drift_check_baselines import DriftCheckBaselines\n",
    "\n",
    "model_quality_model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=model_quality_baseline_step.properties.CalculatedBaselineStatistics,\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    "    model_constraints=MetricsSource(\n",
    "        s3_uri=model_quality_baseline_step.properties.CalculatedBaselineConstraints,\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    "    model_data_statistics=MetricsSource(\n",
    "        s3_uri=data_quality_baseline_step.properties.CalculatedBaselineStatistics,\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    "    model_data_constraints=MetricsSource(\n",
    "        s3_uri=data_quality_baseline_step.properties.CalculatedBaselineConstraints,\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "model_quality_drift_check_baselines = DriftCheckBaselines(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=model_quality_baseline_step.properties.BaselineUsedForDriftCheckStatistics,\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    "    model_constraints=MetricsSource(\n",
    "        s3_uri=model_quality_baseline_step.properties.BaselineUsedForDriftCheckConstraints,\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    "    model_data_statistics=MetricsSource(\n",
    "        s3_uri=data_quality_baseline_step.properties.BaselineUsedForDriftCheckStatistics,\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    "    model_data_constraints=MetricsSource(\n",
    "        s3_uri=data_quality_baseline_step.properties.BaselineUsedForDriftCheckConstraints,\n",
    "        content_type=\"application/json\",\n",
    "    ),\n",
    ")"
   ],
   "id": "b20bf573f3d31eaa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "6fcca9c359dbb57a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "register_model_step = create_registration_step(\n",
    "    pipeline_model,\n",
    "    MODEL_PACKAGE_GROUP,\n",
    "    content_types=[\"text/csv\", \"application/json\"],\n",
    "    response_types=[\"text/csv\", \"application/json\"],\n",
    "    model_metrics=model_quality_model_metrics,\n",
    "    drift_check_baselines=model_quality_drift_check_baselines,\n",
    ")"
   ],
   "id": "5feb3043cf773a1d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from sagemaker.workflow.functions import JsonGet\n",
    "from sagemaker.workflow.fail_step import FailStep\n",
    "from sagemaker.workflow.parameters import ParameterFloat\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "from sagemaker.workflow.conditions import ConditionGreaterThanOrEqualTo\n",
    "\n",
    "f1_threshold = ParameterFloat(name=\"f1_threshold\", default_value=0.64)\n",
    "\n",
    "fail_step = FailStep(\n",
    "    name=\"fail\",\n",
    "    error_message=Join(\n",
    "        on=\" \",\n",
    "        values=[\n",
    "            \"Execution failed because the model's f1 result was lower than\",\n",
    "            f1_threshold,\n",
    "        ],\n",
    "    ),\n",
    ")\n",
    "\n",
    "condition = ConditionGreaterThanOrEqualTo(\n",
    "    left=JsonGet(\n",
    "        step_name=evaluate_model_step.name,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"metrics.f1.value\",\n",
    "    ),\n",
    "    right=f1_threshold,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d8ab4d19cbfc11ae",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# response = sagemaker_client.list_model_packages(\n",
    "#     ModelPackageGroupName=MODEL_PACKAGE_GROUP,\n",
    "#     ModelApprovalStatus=\"Approved\",\n",
    "#     SortBy=\"CreationTime\",\n",
    "#     MaxResults=1,\n",
    "# )\n",
    "# \n",
    "# package = (\n",
    "#     response[\"ModelPackageSummaryList\"][0]\n",
    "#     if response[\"ModelPackageSummaryList\"]\n",
    "#     else None\n",
    "# )\n",
    "\n",
    "# package"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd32108d3539c4c2",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "lambda_role_name = \"lambda-deployment-role\"\n",
    "lambda_role_arn = None\n",
    "\n",
    "try:\n",
    "    response = iam_client.create_role(\n",
    "        RoleName=lambda_role_name,\n",
    "        AssumeRolePolicyDocument=json.dumps(\n",
    "            {\n",
    "                \"Version\": \"2012-10-17\",\n",
    "                \"Statement\": [\n",
    "                    {\n",
    "                        \"Effect\": \"Allow\",\n",
    "                        \"Principal\": {\n",
    "                            \"Service\": [\"lambda.amazonaws.com\", \"events.amazonaws.com\"],\n",
    "                        },\n",
    "                        \"Action\": \"sts:AssumeRole\",\n",
    "                    },\n",
    "                ],\n",
    "            },\n",
    "        ),\n",
    "        Description=\"Lambda Endpoint Deployment\",\n",
    "    )\n",
    "\n",
    "    lambda_role_arn = response[\"Role\"][\"Arn\"]\n",
    "\n",
    "    iam_client.attach_role_policy(\n",
    "        PolicyArn=\"arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole\",\n",
    "        RoleName=lambda_role_name,\n",
    "    )\n",
    "\n",
    "    iam_client.attach_role_policy(\n",
    "        PolicyArn=\"arn:aws:iam::aws:policy/AmazonSageMakerFullAccess\",\n",
    "        RoleName=lambda_role_name,\n",
    "    )\n",
    "\n",
    "    print(f'Role \"{lambda_role_name}\" created with ARN \"{lambda_role_arn}\".')\n",
    "except iam_client.exceptions.EntityAlreadyExistsException:\n",
    "    response = iam_client.get_role(RoleName=lambda_role_name)\n",
    "    lambda_role_arn = response[\"Role\"][\"Arn\"]\n",
    "    print(f'Role \"{lambda_role_name}\" already exists with ARN \"{lambda_role_arn}\".')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a2004f5f8a325cd",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from sagemaker.lambda_helper import Lambda\n",
    "\n",
    "ENDPOINT = \"football-endpoint\"\n",
    "DATA_CAPTURE_DESTINATION = f\"{S3_LOCATION}/monitoring/data-capture\"\n",
    "DATA_CAPTURE_PERCENTAGE = 100\n",
    "\n",
    "deploy_lambda_fn = Lambda(\n",
    "    function_name=\"deployment_fn\",\n",
    "    execution_role_arn=lambda_role_arn,\n",
    "    script=(CODE_FOLDER / \"lambda\" / \"lambda.py\").as_posix(),\n",
    "    handler=\"lambda.lambda_handler\",\n",
    "    timeout=600,\n",
    "    session=sagemaker_session,\n",
    "    runtime=\"python3.11\",\n",
    "    environment={\n",
    "        \"Variables\": {\n",
    "            \"ENDPOINT\": ENDPOINT,\n",
    "            \"DATA_CAPTURE_DESTINATION\": DATA_CAPTURE_DESTINATION,\n",
    "            \"DATA_CAPTURE_PERCENTAGE\": str(DATA_CAPTURE_PERCENTAGE),\n",
    "            \"ROLE\": role,\n",
    "            \"MODEL_PACKAGE_GROUP\": MODEL_PACKAGE_GROUP\n",
    "        },\n",
    "    },\n",
    ")\n",
    "\n",
    "deploy_lambda_fn_response = deploy_lambda_fn.upsert()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4d3b3b8b5a8bf88",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from sagemaker.workflow.lambda_step import LambdaStep\n",
    "\n",
    "\n",
    "def create_deployment_step(register_model_step):\n",
    "    \"\"\"Create a Deploy Step using the supplied parameters.\"\"\"\n",
    "    return LambdaStep(\n",
    "        name=\"deploy\",\n",
    "        lambda_func=deploy_lambda_fn,\n",
    "        inputs={\n",
    "            \"model_package_arn\": register_model_step.properties.ModelPackageArn,\n",
    "        },\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b3f5eb5289dcdb89",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "deploy_step = create_deployment_step(register_model_step)\n",
    "\n",
    "condition_step = ConditionStep(\n",
    "    name=\"check-model-f1-score\",\n",
    "    conditions=[condition],\n",
    "    if_steps=(\n",
    "        [\n",
    "            create_model_step,\n",
    "            generate_test_predictions_step,\n",
    "            model_quality_baseline_step,\n",
    "            deploy_step\n",
    "        ]\n",
    "    ),\n",
    "    else_steps=[fail_step],\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "93920bd415ce9d60",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "session_pipeline = Pipeline(\n",
    "    name=\"session6-pipeline\",\n",
    "    parameters=[dataset_location, f1_threshold],\n",
    "    steps=[\n",
    "        split_and_transform_data_step,\n",
    "        tune_model_step if USE_TUNING_STEP else train_model_step,\n",
    "        evaluate_model_step,\n",
    "        condition_step,\n",
    "    ],\n",
    "    pipeline_definition_config=pipeline_definition_config,\n",
    "    sagemaker_session=config[\"session\"],\n",
    ")\n",
    "\n",
    "session_pipeline.upsert(role_arn=role)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "afc088fa81b0356",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "session_pipeline.start()",
   "metadata": {
    "collapsed": false
   },
   "id": "2a53db12df12f93f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
