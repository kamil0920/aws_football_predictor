{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "feature_names = [\n",
    "    \"player_rating_home_player_1\",\n",
    "    \"player_rating_home_player_2\",\n",
    "    \"player_rating_home_player_3\",\n",
    "    \"player_rating_home_player_4\",\n",
    "    \"player_rating_home_player_5\",\n",
    "    \"player_rating_home_player_6\",\n",
    "    \"player_rating_home_player_7\",\n",
    "    \"player_rating_home_player_8\",\n",
    "    \"player_rating_home_player_9\",\n",
    "    \"player_rating_home_player_10\",\n",
    "    \"player_rating_home_player_11\",\n",
    "    \"player_rating_away_player_1\",\n",
    "    \"player_rating_away_player_2\",\n",
    "    \"player_rating_away_player_3\",\n",
    "    \"player_rating_away_player_4\",\n",
    "    \"player_rating_away_player_5\",\n",
    "    \"player_rating_away_player_6\",\n",
    "    \"player_rating_away_player_7\",\n",
    "    \"player_rating_away_player_8\",\n",
    "    \"player_rating_away_player_9\",\n",
    "    \"player_rating_away_player_10\",\n",
    "    \"player_rating_away_player_11\",\n",
    "    \"ewm_home_team_goals\",\n",
    "    \"ewm_away_team_goals\",\n",
    "    \"ewm_home_team_goals_conceded\",\n",
    "    \"ewm_away_team_goals_conceded\",\n",
    "    \"points_home\",\n",
    "    \"points_away\",\n",
    "    \"home_weighted_wins\",\n",
    "    \"away_weighted_wins\",\n",
    "    \"avg_home_team_rating\",\n",
    "    \"avg_away_team_rating\",\n",
    "    \"home_streak_wins\",\n",
    "    \"away_streak_wins\",\n",
    "    \"ewm_shoton_home\",\n",
    "    \"ewm_shoton_away\",\n",
    "    \"ewm_possession_home\",\n",
    "    \"ewm_possession_away\",\n",
    "    \"avg_home_rating_attack\",\n",
    "    \"avg_away_rating_attack\",\n",
    "    \"avg_away_rating_defence\",\n",
    "    \"avg_home_rating_defence\",\n",
    "    \"average_rating_home\",\n",
    "    \"average_rating_away\",\n",
    "    \"num_top_players_home\",\n",
    "    \"num_top_players_away\",\n",
    "    \"ewm_home_team_goals_conceded_x_ewm_shoton_home\",\n",
    "    \"attacking_strength_home\",\n",
    "    \"attacking_strength_away\",\n",
    "    \"attacking_strength_diff\"\n",
    "]"
   ],
   "id": "65ff5f646ddaa207",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import posixpath\n",
    "import boto3\n",
    "from smdebug.trials import create_trial\n",
    "\n",
    "sm_client = boto3.client('sagemaker')\n",
    "\n",
    "def get_latest_training_job():\n",
    "    training_jobs = sm_client.list_training_jobs(SortBy='CreationTime', SortOrder='Descending')['TrainingJobSummaries']\n",
    "    if training_jobs:\n",
    "        latest_job_name = training_jobs[0]['TrainingJobName']\n",
    "        return latest_job_name\n",
    "    else:\n",
    "        raise Exception(\"No training jobs found\")\n",
    "\n",
    "def get_debugger_artifacts_path(training_job_name):\n",
    "    response = sm_client.describe_training_job(TrainingJobName=training_job_name)\n",
    "    if 'DebugHookConfig' in response and 'S3OutputPath' in response['DebugHookConfig']:\n",
    "        s3_output_path = response['DebugHookConfig']['S3OutputPath']\n",
    "        if not s3_output_path.endswith('/'):\n",
    "            s3_output_path += '/'\n",
    "        return s3_output_path + training_job_name + \"/\"\n",
    "    else:\n",
    "        raise Exception(\"Debugger artifacts path not found for the training job\")\n",
    "\n",
    "latest_training_job_name = get_latest_training_job()\n",
    "print(f\"Latest Training Job Name: {latest_training_job_name}\")\n",
    "\n",
    "bucket = 'football-bucket'\n",
    "key = posixpath.join('train_analyse', latest_training_job_name, 'debug-output', '')\n",
    "\n",
    "debugger_artifacts_path = f's3://{bucket}/{key}'\n",
    "print(f\"Debugger Artifacts Path: {debugger_artifacts_path}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "trial = create_trial(debugger_artifacts_path)\n",
    "trial"
   ],
   "id": "ae46260595600034",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from itertools import islice\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "MAX_PLOTS = 35\n",
    "\n",
    "\n",
    "def get_data(trial, tname):\n",
    "    \"\"\"\n",
    "    For the given tensor name, walks though all the iterations\n",
    "    for which you have data and fetches the values.\n",
    "    Returns the set of steps and the values.\n",
    "    \"\"\"\n",
    "    tensor = trial.tensor(tname)\n",
    "    steps = tensor.steps()\n",
    "    vals = [tensor.value(s) for s in steps]\n",
    "    return steps, vals\n",
    "\n",
    "\n",
    "def match_tensor_name_with_feature_name(tensor_name, feature_names=feature_names):\n",
    "    feature_tag = tensor_name.split(\"/\")\n",
    "    for ifeat, feature_name in enumerate(feature_names):\n",
    "        if feature_tag[-1] == \"f{}\".format(str(ifeat)):\n",
    "            return feature_name\n",
    "    return tensor_name\n",
    "\n",
    "\n",
    "def plot_collection(trial, collection_name, regex=\".*\", figsize=(8, 6)):\n",
    "    \"\"\"\n",
    "    Takes a `trial` and a collection name, and\n",
    "    plots all tensors that match the given regex.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    tensors = trial.collection(collection_name).tensor_names\n",
    "    matched_tensors = [t for t in tensors if re.match(regex, t)]\n",
    "    for tensor_name in islice(matched_tensors, MAX_PLOTS):\n",
    "        steps, data = get_data(trial, tensor_name)\n",
    "        ax.plot(steps, data, label=match_tensor_name_with_feature_name(tensor_name))\n",
    "\n",
    "    ax.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "    ax.set_xlabel(\"Iteration\")"
   ],
   "id": "6cc346c4462f24d2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_collection(trial, 'metrics')",
   "id": "c46726736bf9b451",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_feature_importance(trial, importance_type=\"weight\"):\n",
    "    SUPPORTED_IMPORTANCE_TYPES = [\n",
    "        \"weight\",\n",
    "        \"gain\",\n",
    "        \"cover\",\n",
    "        \"total_gain\",\n",
    "        \"total_cover\",\n",
    "    ]\n",
    "    if importance_type not in SUPPORTED_IMPORTANCE_TYPES:\n",
    "        raise ValueError(f\"{importance_type} is not one of the supported importance types.\")\n",
    "    plot_collection(trial, \"feature_importance\", regex=f\"feature_importance/{importance_type}/.*\")"
   ],
   "id": "da0db35c97131610",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_feature_importance(trial, importance_type=\"cover\")",
   "id": "ea4f1c33abdd1c4d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_collection(trial, \"average_shap\")",
   "id": "51245bc6f9589fbe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import shap\n",
    "\n",
    "shap_values = trial.tensor(\"full_shap/f0\").value(trial.last_complete_step)\n",
    "shap_no_base = shap_values[:, :-1]\n",
    "shap_base_value = shap_values[0, -1]\n",
    "shap.summary_plot(shap_no_base, plot_type=\"bar\", feature_names=feature_names)\n",
    "\n",
    "shap_base_value"
   ],
   "id": "d0c531d99c6d65a2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import boto3\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "%load_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "pipeline_name = os.environ[\"PIPELINE_NAME\"]\n",
    "\n",
    "print(f\"Pipeline Name: {pipeline_name}\")\n",
    "\n",
    "pipeline_executions = sm_client.list_pipeline_executions(\n",
    "    PipelineName=pipeline_name,\n",
    "    SortBy='CreationTime',\n",
    "    SortOrder='Descending',\n",
    "    MaxResults=1\n",
    ")\n",
    "\n",
    "if not pipeline_executions['PipelineExecutionSummaries']:\n",
    "    raise ValueError('No pipeline executions found for the specified pipeline.')\n",
    "\n",
    "latest_execution = pipeline_executions['PipelineExecutionSummaries'][0]\n",
    "execution_arn = latest_execution['PipelineExecutionArn']\n",
    "\n",
    "execution_steps = sm_client.list_pipeline_execution_steps(\n",
    "    PipelineExecutionArn=execution_arn\n",
    ")\n",
    "\n",
    "train_csv_uri = None\n",
    "\n",
    "for step in execution_steps['PipelineExecutionSteps']:\n",
    "    if step['StepName'] == 'split-and-transform-data':\n",
    "        processing_job_arn = step['Metadata']['ProcessingJob']['Arn']\n",
    "        processing_job_name = processing_job_arn.split('/')[-1]\n",
    "        \n",
    "        processing_job_desc = sm_client.describe_processing_job(\n",
    "            ProcessingJobName=processing_job_name\n",
    "        )\n",
    "        \n",
    "        outputs = processing_job_desc['ProcessingOutputConfig']['Outputs']\n",
    "        for output in outputs:\n",
    "            if output['OutputName'] == 'train':\n",
    "                s3_uri = output['S3Output']['S3Uri']\n",
    "                train_csv_uri = f\"{s3_uri}/train.csv\"\n",
    "                print('train.csv S3 URI:', train_csv_uri)\n",
    "        break\n",
    "else:\n",
    "    raise ValueError('The split-and-transform-data step was not found in the latest execution.')\n",
    "\n",
    "\n",
    "if train_csv_uri is None:\n",
    "    raise ValueError('train.csv URI could not be found.')\n",
    "\n",
    "X_train_display = pd.read_csv(train_csv_uri)\n",
    "X_train_display.drop(labels=['result_match'], axis=1, inplace=True)\n",
    "\n",
    "print(X_train_display.head(1))"
   ],
   "id": "5501ea0873e3ef7d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "os.mkdir('plots')\n",
    "\n",
    "N_ROWS = shap_no_base.shape[0]\n",
    "N_SAMPLES = min(100, N_ROWS)\n",
    "sampled_indices = np.random.randint(N_ROWS, size=N_SAMPLES)\n",
    "\n",
    "force_plot = shap.force_plot(\n",
    "    shap_base_value,\n",
    "    shap_no_base[sampled_indices, :],\n",
    "    X_train_display.iloc[sampled_indices, :],\n",
    "    link=\"logit\"\n",
    ")\n",
    "\n",
    "shap.save_html('plots/force_plot.html', force_plot)"
   ],
   "id": "d4d4d1b67f428d74",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from scipy import stats\n",
    "\n",
    "N_OUTLIERS = 3\n",
    "\n",
    "shap_sum = np.sum(shap_no_base, axis=1)\n",
    "z_scores = stats.zscore(shap_sum)\n",
    "outlier_indices = (np.argpartition(z_scores, -N_OUTLIERS)[-N_OUTLIERS:]).tolist()\n",
    "outlier_indices += (np.argpartition(z_scores, N_OUTLIERS)[:N_OUTLIERS]).tolist()\n",
    "\n",
    "shap.initjs()\n",
    "\n",
    "for fig_index, outlier_index in enumerate(outlier_indices, start=1):\n",
    "    force_plot = shap.force_plot(\n",
    "        shap_base_value,\n",
    "        shap_no_base[outlier_index, :],\n",
    "        X_train_display.iloc[outlier_index, :],\n",
    "        matplotlib=False,\n",
    "        link=\"logit\",\n",
    "    )\n",
    "\n",
    "    shap.save_html(f'plots/force_plot_{fig_index}.html', force_plot)\n",
    "    \n",
    "    print(f\"Saved force plot {fig_index} for index {outlier_index} to force_plot_{fig_index}.html\")\n"
   ],
   "id": "42933e9e8ee0dca3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "1aba7d1ef1cecec",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
